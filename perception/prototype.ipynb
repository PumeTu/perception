{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def get_activation(name: str =\"silu\", inplace: bool =True):\n",
    "    '''\n",
    "    Get an activation function given the name\n",
    "    Args:\n",
    "        name (str): name of desired activation function\n",
    "        inplace (bool): specify whether to the operation inplace or not\n",
    "    Returns\n",
    "        module (nn.Module): activation function requested\n",
    "    '''\n",
    "    if name == \"silu\":\n",
    "        module = nn.SiLU(inplace=inplace)\n",
    "    elif name == \"relu\":\n",
    "        module = nn.ReLU(inplace=inplace)\n",
    "    elif name == \"lrelu\":\n",
    "        module = nn.LeakyReLU(0.1, inplace=inplace)\n",
    "    else:\n",
    "        raise AttributeError(\"Unsupported activation function: {}\".format(name))\n",
    "    return module\n",
    "\n",
    "class BaseConv(nn.Module):\n",
    "    '''\n",
    "    Basic Convloutional Block (Conv -> BatchNorm -> ReLU/SiLU)\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int): size of kernel\n",
    "        stride (int): stride length\n",
    "        groups (int): convolution group\n",
    "        bias (bool): add bias or not\n",
    "        activation (str): name of activation function\n",
    "    '''\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, groups:int =1, bias: bool =False, activation: str ='silu'):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2 #same padding\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03)\n",
    "        self.act = get_activation(activation, inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.act(self.batchnorm(self.conv(x)))\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    '''\n",
    "    Basic Residual Block as defined in the ResNet paper with two convolutional layers and a skip connection\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "    '''\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        reduced_channels = in_channels // 2\n",
    "        self.conv1 = BaseConv(in_channels, reduced_channels, kernel_size=1, stride=1, activation='lrelu')\n",
    "        self.conv2 = BaseConv(reduced_channels, in_channels, kernel_size=3, stride=1, activation='lrelu')\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        out = self.conv2(self.conv1(x))\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Darknet53(nn.Module):\n",
    "    '''\n",
    "    Base Darknet53 based on the YOLOv3 paper\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        stem_out_channels (int): number of output channels for first convolutional layer\n",
    "        output (tuple): output layers to return\n",
    "    '''\n",
    "    def __init__(self, in_channels: int, stem_out_channels: int = 32, output: tuple = ('c3', 'c4', 'c5')):\n",
    "        super().__init__()\n",
    "        self.output = output\n",
    "        num_blocks = [2, 8, 8, 4]\n",
    "        self.c1 = nn.Sequential(\n",
    "            BaseConv(in_channels, stem_out_channels, kernel_size=3, stride=1, activation='lrelu'),\n",
    "            *self._build_group_block(in_channels=stem_out_channels, num_blocks=1, stride=2))\n",
    "        in_channels = stem_out_channels * 2\n",
    "        self.c2 = nn.Sequential(\n",
    "            *self._build_group_block(in_channels=in_channels, num_blocks=num_blocks[0], stride=2))\n",
    "        in_channels = in_channels * 2\n",
    "        self.c3 = nn.Sequential(\n",
    "            *self._build_group_block(in_channels=in_channels, num_blocks=num_blocks[1], stride=2))\n",
    "        in_channels = in_channels * 2\n",
    "        self.c4 = nn.Sequential(\n",
    "            *self._build_group_block(in_channels=in_channels, num_blocks=num_blocks[2], stride=2))\n",
    "        in_channels = in_channels * 2\n",
    "        self.c5 = nn.Sequential(\n",
    "            *self._build_group_block(in_channels=in_channels, num_blocks=num_blocks[3], stride=2))\n",
    "\n",
    "    def _build_group_block(self, in_channels: int, num_blocks: int, stride: int):\n",
    "        '''\n",
    "        Build convolutional layer -> Residual Block (repeated num_blocks times)\n",
    "        '''\n",
    "        return [\n",
    "            BaseConv(in_channels, in_channels*2, kernel_size=3, stride=stride),\n",
    "            *[(Residual(in_channels*2)) for _ in range(num_blocks)]\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "        x = self.c1(x)\n",
    "        outputs['c1'] = x\n",
    "        x = self.c2(x)\n",
    "        outputs['c2'] = x\n",
    "        x = self.c3(x)\n",
    "        outputs['c3'] = x\n",
    "        x = self.c4(x)\n",
    "        outputs['c4'] = x\n",
    "        x = self.c5(x)\n",
    "        outputs['c5'] = x\n",
    "        return {k:v for k, v in outputs.items() if k in self.output}\n",
    "\n",
    "class Perception(nn.Module):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3: torch.Size([2, 256, 52, 52])\n",
      "c4 :torch.Size([2, 512, 26, 26])\n",
      "c5: torch.Size([2, 1024, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "model = Darknet53(in_channels=3, stem_out_channels=32)\n",
    "x = torch.randn(2, 3, 416, 416)\n",
    "out = model(x)\n",
    "print(f\"c3: {out['c3'].shape}\")\n",
    "print(f\"c4 :{out['c4'].shape}\")\n",
    "print(f\"c5: {out['c5'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
